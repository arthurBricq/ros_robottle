# Robottle Controller 1

First Robot Autonomous Controller is a State Machine performing Random Walk to Collect bottles. This files reports a documentation of this controller and lays out what needs to be done.

![controller](imgs/controller1.png)

## A word about the map representation

Our map is represented using a 2d occupancy grid, one key problem is the origin of this map.

One the numpy array, the first index represents the rows (i.e. the y-coordinates) and the second index represents the the columns, hence the x-position of the array.
- if the map is plot using `plt.imshow` then the origin is at the lower-left corner
- if the map is plot using `cv2.save()` then the origin is at the upper-left corner

About the positions and the orientation within the map, it's defined with the origin being the horizontal line and positive rotations clokwise.

## State Machine Description

A state machine is implemented and contains several state, describe here

- INITIAL ROTATION MODE 
- TRAVEL MODE 
- RANDOM SEARCH MODE 
- BOTTLE PICKING MODE 
- BOTTLE RELEASE MODE

What defines the 'pace' of the controller are the different callbacks from other ROS Node. As they play an important role for the state machine, let me recall which those are

- SLAM callback: it's in charge of calling the TRAVEL MODE.
- Camera callback: it's in charge of the robot in two situations
    - RANDOM SEARCH MODE: it says the angles where are bottles, to estimate the remaining rotation time required.
    - BOTTLE PICKING MODE: it says when the bottle that is in front of the robot is in range to be picked by the arms.
- Arduino callback: it's in charge of receiving messages from the arduino
    - BOTTLE PICKING MODE: after the robot reached the bottle and tried to picked it
    - BOTTLE RELEASE MODE: after the robot performed a rotation and a driving backward and have asked to open the back door

### Travel Mode

In this state, the robot must travel to another zone - where we know it's going to make more points. Several situations can occurs:
1. The robot will go pick bottles in another new (*not explored*) zone: **exploration mode**. For now, we assume in this mode that the robot is in the recycling area and that it is empty. 
2. The robot will come back at the **recycling area** to drop its bottles: **return mode**. 

Implementation details
- the function `travel_mode` which is in charge of the **path planning** (computed once in a while) and of the **path tracking**. The function is called by the map callback if the state is activated.

**Discussions**

What information does the algorithm needs to **make the robot travel to the desired zone** ?
- (i1) = **the desired zone**: it is easy to get those, we simply keep an array `desired_zones` and `visited_zones`, then make a substraction of those 2 sets to extract where we want to go.
- (i2) = **robot state & environment**: it is the output of the SLAM (*needs an evaluation*)
- (i3) = **position of the desired end position in the environment**: this is the hardest part. We must have a desired position in term of the occupancy grid, but the occupancy is a variable that we do not control and that evolves as the robot moves. 

**How can we find (i3)**

First thing to be said is that (i3) is not a constant and **it will be re-evaluated** as the robot moves. **There is a strong required coupling between path planning and path following**, and this is the case because we have a **dynamic map construction**. 

So what data can we use to deduce (i3) if we assume to have at disposition (i1) + (i2)...
- Prior knowledge of the **real map**
    - the real map is a square
    - the real map contains a ramp in a given position
    - the real map has 4 color beacons

We find those points using the `map_analysis` functions. Those are well documented and explains all the steps. 

**Path planning and path following**

DISCLAMER: The algorihtm relies on two very important hypothesis: (i) that the map is embeded within the SLAM's map and that (ii) the robot is located near the recycling area, with the ability to perform an initial 360 degrees rotation. How can this be achieved ? 
- place the robot near the recycling area, facing towards the 'rock' area. With this setup, it will work
- it may be possible (if we have time) to automatically detect the orientation of the robot. 

RRTStar algorithm was implemented for path planning.

For the path following, it works the following way:
- at a certain rate (defined by an update time constant) a path is generated by the path planning algorithm.
- if the robot is close to the goal, then it will leave the travel mode
- else, another state machine takes places: "rotation correction" or "forward" submodes
    - if "rotation correction": robot will rotate until reaching the desired orientation. This mode is launched autmatically if the direction of the robot is not aligned with the direction of the path. 
    - if "forward": robot will simply move forward until next rotation mode is launched.

### Random walk Mode

Rotates slowly until a bottle is in front of the robot.

### Bottle Picking Mode

A bottle is in front of the robot: moves straigth until the bottle **is in range of the arm** (this idication is given by analysing the bounding boxes of the NN and by combining this information with Lidar data)

Then, send a message to Arduino Mega via UART saying "you are now in charge of picking the bottle".

The Arduino mega will
- try to catch the bottle 
    - if no bottle is detected --> responds "I can't find a bottle"
    - if bottle is detected but can't be picked --> tries 1 more time. If unsucessfull again, responds "I can't pick this bottle" and the Jetson will need to move (**recovery mode**)
    - if bottle is collected --> responds "I picked the bottle !"


### Recovery Mode

This mode will be writen when we have more empirical data on the problems and how to fix them. 

# Debuging 

## bag files
- test0 mercantour: motors speed corructed hence SLAM is not working
- test0 arena slow: 
    - SLAM is constantly shifting to the right, it's quite weird.
    - SLAM is not updated many times, it's stopping at some point when really it shouldn't. Looks like there is a problem with this dataset as well since once SLAM stops working then i can't close the simulation from running. Is it corrupted ? 

## things to test
- size of the lidar packages : are they too small ? maybe sometimes it is the case
- how can we filter the map ? It looks like many times there are other lines. I need a better vizualisation tool which can plot a numpy array





